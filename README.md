# AutoSvc

## An enhanced version of the [AutoVC system](https://github.com/auspicious3000/autovc)

This repository presents a voice conversion model with many customisations for additional features and design adaptations. It is specifically designed for singing voice attribute conversion.

Extra features include:
- Ability to use an singer indentity embedding (SIE) model with different features as input
- Use of multiple WORLD feature configurations
- Pitch conditioning and Early-stopping mechanisms
- Integration of several normalisation techniques
- Use of singer embedding lookup table
- Extended user customisability via the ```train_params.py``` file


This repository has now been redesigned to be used in conjunction with our [Singer Identity Embedding (SIE) Encoder repository](https://github.com/Trebolium/singer-identity-encoder). A combined use of the two is available [here](https://github.com/Trebolium/singer_identity_converter).

We advise users to experiment with the use of variables that can be accessed either from python parameter files or the argparsing interface. In particular, users will want to change the file paths to access files and datasets they may have stored locally.



## Instructions

If you do not wish to train your own models, you can download pretrained ones here (WAveNet link is reposted from the AutoVC repository):

| AUTOSVC | SIE | WaveNet Vocoder |
|----------------|----------------|----------------|
| [link](https://drive.google.com/drive/folders/1Ng-WW9d9WsayOmcRm4igTj7iw_hYo4kD?usp=sharing)| [link](https://drive.google.com/file/d/1a-ehZUcg0ybRfjmS7IeYOl6LXYc5MuQE/view?usp=sharing) | [link](https://drive.google.com/file/d/1Zksy0ndlDezo9wclQNZYkGi_6i7zi4nQ/view?usp=sharing) |

### Training phase

You can either keep the default paths variables unchanged and have our SIE encoder cloned into the same repo as this one, or change the relevant pathnames to point towards the directories you require. In any case, running ```python main.py``` will train the AutoSac network. However please note that the values for size of training iterations and max iterations are extremely small, and will likely need to be adjusted for any training towards useful inference.

### Conversion phase

You will need to download the WaveNet model, available at the original [repository](https://github.com/auspicious3000/autovc). If this does not work, please contact me.

Simply running ```python pitchmatched_conversion.py ``` will by default search for the model manually trained in the previous step. If you wish to use the pretrained model or train your own model, download it or train it, and make sure it is saved in the ```models``` directory, and use the flag ```model_name``` to specify which model is to be used for voice conversion. You must also make sure that lookup tables generated by this pretrained model are available in the ```voice_embs_visuals_metadata``` directory in an parent directory containing this repository.

#### Use pretrained models

A zip files containing a trained singing voice converter model can be downloaded [here](https://drive.google.com/drive/folders/1D7-FzIhgy__IoV0v7LC78QzC6bZA2yKQ?usp=sharing). This has been trained for 2 million iterations of the Intonation DAMP dataset with pitch conditioning. It can be used for converting audio files from a source to target singer. All parameters are saved in the ```this_train_params.py``` file. Alternatively if no pitch features are available, you can also download [another version](https://drive.google.com/drive/folders/1Ng-WW9d9WsayOmcRm4igTj7iw_hYo4kD?usp=sharing), trained for 500k iterations on a quarter of the dAMP dataset, without pitch conditioning. Download these files to the ```autosvc_models``` repository and unzip them. Make sure the ```--model_name``` and ```--checkpoint_name``` options of ```pitchmathced_conversion.py``` are set to the appropriate model name and checkpoint filename respectively.

