{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle, yaml, sys, torch, random, math, librosa, pdb\n",
    "from torch.backends import cudnn\n",
    "import soundfile as sf\n",
    "from synthesis.synthesis import build_model\n",
    "from synthesis.synthesis import wavegen\n",
    "import numpy as np\n",
    "import utils\n",
    "import pyworld as pw\n",
    "from model_vc import Generator\n",
    "from utils import setup_sie, setup_gen\n",
    "sys.path.insert(1, '/homes/bdoc3/my_utils')\n",
    "from audio.worldvocoder import chandna_feats, mfsc_to_sp, midi_to_worldf0, mfsc_to_world_to_audio\n",
    "from my_os import recursive_file_retrieval\n",
    "from my_arrays import fix_feat_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser data\n",
    "svc_model_name = 'withF0chandna_to_500_unnormed'\n",
    "svc_model_dir = '/homes/bdoc3/my_data/autovc_models/autoSvc'\n",
    "svc_ckpt_iters = 252500\n",
    "which_cuda = 1\n",
    "feature_dir = '/homes/bdoc3/my_data/world_vocoder_data/damp_inton/withF0chandna_to_500_unnormed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine relevant paths and yaml files based on user input\n",
    "autovc_model_dir = os.path.join(svc_model_dir, svc_model_name)\n",
    "autosvc_config = pickle.load(open(autovc_model_dir +'/config.pkl','rb'))\n",
    "autosvc_config.autovc_ckpt = os.path.join(autovc_model_dir, 'ckpts', f'ckpt_{svc_ckpt_iters}.pth.tar')\n",
    "with open(feature_dir +'/feat_params.yaml') as File:\n",
    "    feat_params = yaml.load(File, Loader=yaml.FullLoader)\n",
    "subdir_for_wavs = os.path.join(autovc_model_dir, 'generated_wavs')\n",
    "if os.path.exists(subdir_for_wavs)==False:\n",
    "            os.makedirs(subdir_for_wavs)\n",
    "\n",
    "# determine other derivative variables\n",
    "autosvc_which_cuda = which_cuda\n",
    "autosvc_config.device = torch.device(f'cuda:{autosvc_which_cuda}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/homes/bdoc3/my_data/world_vocoder_data/damp_inton/withF0chandna_to_500_unnormed/val/1198871647/1198871647_1859856826.npy', '/homes/bdoc3/my_data/world_vocoder_data/damp_inton/withF0chandna_to_500_unnormed/val/575984180/575984180_1660276054.npy', '/homes/bdoc3/my_data/world_vocoder_data/damp_inton/withF0chandna_to_500_unnormed/val/1224937687/1224937687_1849548794.npy', '/homes/bdoc3/my_data/world_vocoder_data/damp_inton/withF0chandna_to_500_unnormed/val/1427897033/1427897033_1721850720.npy']\n"
     ]
    }
   ],
   "source": [
    "file_path = '/import/c4dm-datasets/NUS_corpus/MPOL/sing/19.wav'\n",
    "\n",
    "feats_ids = ['1014969323_1909869121', '1026003246_1660051761'] # female alto (low) and falsetto tenor (high)\n",
    "dataset_root = '/import/c4dm-datasets/DAMP_Intonation_Dataset/vocal_tracks'\n",
    "file_ext = '.m4a'\n",
    "\n",
    "feats_paths = [os.path.join(feature_dir, 'val', a_id.split('_')[0], a_id)+'.npy' for a_id in feats_ids]\n",
    "\n",
    "user_input = '/homes/bdoc3/my_data/world_vocoder_data/damp_inton/withF0chandna_to_500_unnormed/val'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if input is not file type\n",
    "if os.path.isdir(user_input):\n",
    "    subdir_list, file_path_list = recursive_file_retrieval(user_input)\n",
    "    selected_file_paths = random.choices(file_path_list, k=num_files)\n",
    "    user_input = selected_file_paths\n",
    "else:\n",
    "    file_paths = [user_input]\n",
    "\n",
    "feats_list = []\n",
    "for file in file_paths\n",
    "    if not file.endswith('.npy'):\n",
    "        # assume its audio file\n",
    "        audio, _ = librosa.load(file_path, sr=feat_params['sr'])\n",
    "        feats = chandna_feats(formatted_audio.astype('double'), feat_params)\n",
    "        feats_list.append(feats)\n",
    "    else:\n",
    "        feats_list.append(np.load(file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.insert(1, autovc_model_dir)\n",
    "# from this_model_vc import Generator\n",
    "\n",
    "G = setup_gen(autosvc_config, Generator, feat_params['num_feats'])\n",
    "sie = setup_sie(autosvc_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_offsets = []\n",
    "autosvc_svc_timesteps = 160\n",
    "\n",
    "def infer(feats_paths, si_encoder, autosvc_G):\n",
    "    \"feeds features into framework and outputs list containing outputs and paths\"\n",
    "    feats_list = [torch.from_numpy(np.load(feat_path)).to(autosvc_config.device).float() for feat_path in feats_paths] # convert to torch objects\n",
    "    outputs_sources_list = []\n",
    "    for trg_path, trg_feats in zip(feats_paths, feats_list):\n",
    "        feats_numpy = trg_feats.cpu().detach().numpy()\n",
    "        synthed_audio = mfsc_to_world_to_audio(feats_numpy[:,:feat_params['num_feats']-4], feats_numpy[:,feat_params['num_feats']-4:-2], feats_numpy[:,-2:], feat_params)\n",
    "        sf.write(subdir_for_wavs +f'/{os.path.basename(trg_path)[:-4]}.wav', synthed_audio, samplerate=feat_params['sr'])\n",
    "        \n",
    "        for src_path, src_feats in zip(feats_paths, feats_list):\n",
    "            \n",
    "#             trimmed_feats_list = [trim_feat_length(feats, autosvc_svc_timesteps) for feats in [trg_feats, src_feats]]\n",
    "#             spec_env_list = [trimmed_feats[:,:feat_params['num_feats']] for trimmed_feats in trimmed_feats_list]\n",
    "            trimmed_trg_feats = trim_feat_length(trg_feats, autosvc_svc_timesteps)\n",
    "            trimmed_src_feats = trim_feat_length(src_feats, autosvc_svc_timesteps)\n",
    "            spec_env_trg = trimmed_trg_feats[:,:feat_params['num_feats']]\n",
    "            spec_env_src = trimmed_src_feats[:,:feat_params['num_feats']]\n",
    "            src_pitch_feats = trimmed_src_feats[:,feat_params['num_feats']:]\n",
    "            src_pitch_feats_np = src_pitch_feats.cpu().detach().numpy()\n",
    "            si_emb, _ = si_encoder(spec_env_trg.unsqueeze(0))\n",
    "            _, psnt_output, _, _, _ = autosvc_G(spec_env_src.unsqueeze(0), si_emb, si_emb)\n",
    "            psnt_output_np = psnt_output.cpu().detach().numpy().squeeze(0).squeeze(0)\n",
    "#             print('inner', trg_path, src_path)\n",
    "            outputs_sources_list.append((psnt_output_np, src_pitch_feats_np, trg_path, src_path))\n",
    "            \n",
    "        trimmed_trg_feats = trim_feat_length(trg_feats, autosvc_svc_timesteps)\n",
    "        trimmed_trg_feats_np = trimmed_trg_feats.cpu().detach().numpy()\n",
    "        trg_pitch_feats_np = trimmed_trg_feats_np[:,feat_params['num_feats']:]\n",
    "#         print('outer', trg_path)\n",
    "        outputs_sources_list.append((trimmed_trg_feats_np, trg_pitch_feats_np, 'path/to/original.npy', trg_path))\n",
    "        \n",
    "    return outputs_sources_list\n",
    "\n",
    "outputs_sources_list = infer(feats_paths, sie, G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "for i, (feats, src_pitch_feats, trg_path, src_path) in enumerate(outputs_sources_list):\n",
    "    print(i)\n",
    "    harm_mfsc, ap_mfsc = feats[:,:40], feats[:,40:44]\n",
    "    midi_voicings = src_pitch_feats\n",
    "#     pdb.set_trace()\n",
    "    synthed_audio = mfsc_to_world_to_audio(harm_mfsc, ap_mfsc, midi_voicings, feat_params)\n",
    "    trg_singer, src_singer = os.path.basename(trg_path)[:-4], os.path.basename(src_path)[:-4]\n",
    "    sf.write(subdir_for_wavs +f'/-source-{src_singer}-target-{trg_singer}.wav', synthed_audio, samplerate=feat_params['sr'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WaveNet was trained on 80 mel spectrogram. not suitable for 40 mel spectral envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_synth = build_model().to(autosvc_config.device)\n",
    "voice_synth.load_state_dict(synth_voice_ckpt[\"state_dict\"])\n",
    "voice_synth.to(autosvc_config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "results = pickle.load(open('results.pkl', 'rb'))\n",
    "# subdir_for_conversion = subdir_for_wavs +'/conversions'\n",
    "# if os.path.exists(subdir_for_conversion)==False:\n",
    "#     os.makedirs(subdir_for_conversion)\n",
    "result = results[0]\n",
    "name = result[0]\n",
    "c = result[1]\n",
    "print(name, c[:].shape, type(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "waveform = wavegen(voice_synth, 1, c=c) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  \n",
    "#     librosa.output.write_wav(name+'.wav', waveform, sr=16000)\n",
    "#     sf.write(subdir_for_conversion +'/' +name +'.wav', waveform, samplerate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "for i, (feats, na, nb) in enumerate(outputs_sources_list):\n",
    "    feats_reshaped = feats.cpu().detach().numpy().squeeze(0).squeeze(0)\n",
    "    pdb.set_trace()\n",
    "    waveform = wavegen(voice_synth, 1, c=feats_reshaped)\n",
    "#     waveform = wavegen(voice_synth, autosvc_which_cuda, c=feats_reshaped)\n",
    "    sf.write(subdir_for_wavs +f'/sourceId_{na}_to_targetId_{nb}.wav', waveform, samplerate=feat_params['sr'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvautovc",
   "language": "python",
   "name": "venvautovc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
